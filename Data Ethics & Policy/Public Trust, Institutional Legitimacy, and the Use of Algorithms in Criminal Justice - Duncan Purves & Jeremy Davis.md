#LIS461 #Ethics #Philosophy

## Thesis

In this paper we raise a novel moral concern with algorithmic opacity, one that arises from the relationship between algorithmic opacity and the trustworthiness of criminal justice institutions. In particular, we argue that algorithmic opacity can undermine the trustworthiness of criminal justice institutions, which threatens their legitimacy. This problem can persist even when predictive algorithms satisfy reasonable standards of fairness and when they are more accurate than humans in the same domain (3). 

## Intro

### Quotes

- Courts and law enforcement agencies across the U.S., as well as certain other countries, employ predictive algorithms for a variety of purposes, including risk assessment in sentencing, predicting locations where crime is likely to occur, and identifying those likely to commit criminal acts in the near future (2)
- There is no consensus definition of algorithmic opacity, but we understand an algorithm to count as opaque to some degree just in case (a) facts about the contribution of any single feature of the world to the algorithm’s final determination cannot be easily accessed, either by the human decision-maker or by persons affected by the determination, or (b) the way that the algorithmic determination figures in decision-making cannot be easily understood (2).

## Trust and Trustworthiness

The authors examine an argument by Karen Jones on the "three-place" account of trustworthiness and whether it applies to the trust between an institution and a user, rather than two people (and a domain of interaction). 
Jone's 

### Quotes
- If being trustworthy requires taking the fact of another’s dependence to be a reason to act as counted on, then being trustworthy seems to require the possession of a capacity to respond to facts as reasons.