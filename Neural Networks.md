#MIT #DeepLearning #ML 

Neural networks (NNs) are made up of layers of perceptrons which map an input $x$ to an output $y$ with a linear function and a non-linear activation after. The number of layers between the input and output, called **hidden layers**, is variable. 

NNs also rely on a **learning rate**, which dictates the 