Data Parallelism trains a model in parallel, but Model Parallelism trains a model over multiple GPUs. There are g