We've set up processes to have virtual memory, but how do we decide how much memory a process needs? 
We define the working set for a process at time $t$ as $W(D,t)$, where $D$ is a window of time and $W$ ends up being an approximation of the program's locality. We can give a process an amount of memory that is a function of the amount of pages it has used in the last time step (and if it's the first time the program has run, guess). 
This also works as a function of page faults. More page faults means we need more memory, and vice versa. 
All information related to the working set is stored in the PCB. 

If you take the curve relating the number of page frames to the page fault rate, you can find a point of inflection that acts as that approximation for the correct working set size. 